{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives](#Learning-Objectives)\n",
    "* [Pandas Exercise 3: Relational Normalization](#Pandas-Exercise-3:-Relational-Normalization)\n",
    "\t* [Background on Reading Excel](#Background-on-Reading-Excel)\n",
    "\t* [Background on Relational Normalization](#Background-on-Relational-Normalization)\n",
    "\t* [Background on Categorical Data](#Background-on-Categorical-Data)\n",
    "\t* [Set-up](#Set-up)\n",
    "\t* [Part 1: Read the data](#Part-1:-Read-the-data)\n",
    "\t* [Part 2: Normalize](#Part-2:-Normalize)\n",
    "\t* [Part 3: Create a Sqlite3 database](#Part-3:-Create-a-Sqlite3-database)\n",
    "\t* [Part 4: Compare file sizes](#Part-4:-Compare-file-sizes)\n",
    "\t* [Part 5: Optional](#Part-5:-Optional)\n",
    "\t* [Part 6: Optional](#Part-6:-Optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of this module, learners should be able to:\n",
    "* list various python modules used for reading Excel files\n",
    "* read an Excel data file into a pandas DataFrame\n",
    "* use categorials and other techniques to reduce data size\n",
    "* use pandas to convert an Excel file into an Sqlite database file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Exercise 3: Relational Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on Reading Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several 3rd party Python modules for working with Microsoft Excel spreadsheets.  A list of them is collected at:\n",
    "\n",
    "* [Working with Excel Files in Python](http://www.python-excel.org/)\n",
    "\n",
    "I've used [openpyxl](https://openpyxl.readthedocs.org/en/latest/) successfully in some projects.\n",
    "\n",
    "However, within the Scientific Python toolstack, the most common way of accessing the Excel format is the [Pandas](http://pandas.pydata.org/) framework. This is heavier weight than other options if all you wanted to do was read Excel, but in a scientific context, you already need most of the requirements (NumPy, etc), and you probably want to be using Pandas for numerous other purposes anyway.\n",
    "\n",
    "Pandas relies internally uses `xlrd` to read Excel files, but provides a higher-level wrapper. You probably need to run:\n",
    "\n",
    "```bash\n",
    "conda install xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on Relational Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description from [Wikipedia](https://en.wikipedia.org/wiki/Database_normalization):\n",
    "> *Database normalization ... is the process of organizing the columns (attributes) and tables (relations) of a relational database to minimize data redundancy. Normalization involves decomposing a table into less redundant tables without losing information*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description from the [documentation](https://pandas-docs.github.io/pandas-docs-travis/categorical.html):\n",
    "\n",
    "> *Categoricals are a pandas data type, which correspond to categorical variables in statistics: **a variable, which can take on only a limited, and usually fixed, number of possible values** (categories; levels in R). Examples are gender, social class, blood types, country affiliations, observation time or ratings via Likert scales.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical example: notice the counts for each category\n",
    "import pandas as pd\n",
    "s = pd.Series(pd.Categorical([\"a\",\"b\",\"c\",\"c\",\"e\"], categories=[\"c\",\"a\",\"b\",\"d\"]))\n",
    "\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical example: notice the NaN for a value that did not match any category\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Optional: Uncomment to install the python module `xlrd` for reading Excel files\n",
    "## Recommendation: use the built-in pandas methods instead.\n",
    "\n",
    "#     !conda install -y xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required: imports needed in this exercise\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the NYC Harbor data from the excel data file ``data/nyc_harbor_wq_2006-2014.xlsx`` into DataFrame.\n",
    "\n",
    "*Note: This Excel file is roughly 24 MB in size, contining 300k rows of largely categorical data. It may take some time to load...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solution:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large fraction of all values in a given column are duplicates.\n",
    "* Use the unique `STATION` values as categories to reduce data duplication stored in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create a Sqlite3 database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the NYC Harbor data set, create an Sqlite3 single-file database containing all of the data inside the spreadsheet.\n",
    "\n",
    "* Store the data in its native types per column/cell (Pandas does a good job of inferring data types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Compare file sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that compares the file size of the resulting sqlite3 file compared to the original Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose some interesting queries of the database to extract patterns or features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have access configured, try the exercise using a general purpose RDBMS, such as MySQL, PostgreSQL, SQL Server, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to the normalization, we might notice that our Pandas `DataFrame` itself is inefficient for the same reasons that normalization is desirable.  A large number of copies of the same strings are stored within the same column `Series` objects.  Moreover, in many cases what is stored are strings which need to be stored as Python objects, and processed much more slowly and indirectly than with basic numeric types that leverage their underlying `numpy` arrays.  We can improve this quite a bit."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "continuum": {
   "depends": [
    "pd_intro",
    "pd_data_io"
   ],
   "requires": [
    "data/nyc_harbor_wq_2006-2014.xlsx"
   ],
   "tag": "pd_ex_excel"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
