{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives](#Learning-Objectives)\n",
    "* [Pandas: Time Series](#Pandas:-Time-Series)\n",
    "\t* [Set-Up](#Set-Up)\n",
    "* [Short Demo: Weather Data](#Short-Demo:-Weather-Data)\n",
    "\t* [Read data](#Read-data)\n",
    "\t* [Resampling](#Resampling)\n",
    "\t* [Compute Rolling Mean](#Compute-Rolling-Mean)\n",
    "* [Long Demo: NYC Bicycle Share Data](#Long-Demo:-NYC-Bicycle-Share-Data)\n",
    "\t* [Data Download](#Data-Download)\n",
    "\t* [Data Read](#Data-Read)\n",
    "\t* [Data Resampling](#Data-Resampling)\n",
    "\t* [Data Visualization](#Data-Visualization)\n",
    "\t* [Data Group Separation](#Data-Group-Separation)\n",
    "\t\t* [Motivation](#Motivation)\n",
    "\t\t* [Steps](#Steps)\n",
    "* [Time Series Operations](#Time-Series-Operations)\n",
    "\t* [Frequency](#Frequency)\n",
    "\t* [Time Zones](#Time-Zones)\n",
    "\t* [Time Deltas](#Time-Deltas)\n",
    "\t* [Time Resampling](#Time-Resampling)\n",
    "\t* [Missing Values](#Missing-Values)\n",
    "* [Computational Tools](#Computational-Tools)\n",
    "* [Section Review](#Section-Review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this notebook, the learner will be able to use pandas to:\n",
    "* Perform exploratory data analysis of time series data\n",
    "* Read, filter, and resample time series data\n",
    "* Index time series data by time steps of different sizes\n",
    "* Convert time zones in a time series\n",
    "* Compute summary statistics and rolling statistics of time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas: Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 12\n",
    "pd.options.display.max_columns = 8\n",
    "pd.options.display.width = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Demo: Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/pittsburgh2013.csv', parse_dates=True, index_col='Date')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect data columns\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect data times\n",
    "\n",
    "weather.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simply plotting with matplotlib\n",
    "\n",
    "weather['Mean TemperatureF'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fancy plotting with Bokeh\n",
    "# !conda install -y bokeh=0.11\n",
    "\n",
    "import bokeh \n",
    "bokeh.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "\n",
    "# construct figure object\n",
    "fig = figure( x_axis_type=\"datetime\", responsive=True, height=200 )\n",
    "\n",
    "# plot line on figure\n",
    "fig.line( weather.index, weather['Mean TemperatureF'] )\n",
    "\n",
    "# Make pretty\n",
    "fig.title            = 'Mean TemperatureF'\n",
    "fig.xaxis.axis_label = 'Date'\n",
    "fig.yaxis.axis_label = 'Temp °F'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall the data frequency is daily\n",
    "\n",
    "weather['Mean TemperatureF'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resampling every 4 hours\n",
    "\n",
    "weather['Mean TemperatureF'].resample('4h').head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resampling with \"forward-fill\"\n",
    "\n",
    "weather['Mean TemperatureF'].resample('4h').ffill().head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Rolling Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biweekly_mean_temp = pd.rolling_mean(weather['Mean TemperatureF'], freq='W', window=2)\n",
    "biweekly_mean_temp.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekly_mean_temp = weather['Mean TemperatureF'].resample('W') # default resampling uses mean()\n",
    "weekly_mean_temp.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a bokeh figure\n",
    "from bokeh.plotting import figure\n",
    "fig = figure(x_axis_type=\"datetime\", responsive=True, height=200)\n",
    "\n",
    "# Label the figure\n",
    "fig.xaxis.axis_label='Date'\n",
    "fig.yaxis.axis_label='Temp °F'\n",
    "fig.title = 'Bi Weekly Rolling Mean'\n",
    "\n",
    "# plot line, weekly mean\n",
    "fig.line(weekly_mean_temp.index, weekly_mean_temp, \n",
    "         color='blue', legend='Weekly Mean')\n",
    "\n",
    "# plot line, biweekly rolling mean\n",
    "fig.line(biweekly_mean_temp.index, biweekly_mean_temp, \n",
    "         color='red', legend='Bi Weekly Rolling Mean')\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Demo: NYC Bicycle Share Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This example is inspired by a nice blog on Seattle bikeshare written by Jake VanDerPlas:\n",
    "\n",
    "https://jakevdp.github.io/blog/2015/10/17/analyzing-pronto-cycleshare-data-with-python-and-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've downloading similar data for the NYC bicycle share program:\n",
    " * Data for all dates: https://www.citibikenyc.com/system-data\n",
    " * Data for 2015 September: https://s3.amazonaws.com/tripdata/201509-citibike-tripdata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Large file. This read takes 15-20 seconds on my MacBookPro\n",
    "df = pd.read_csv('data/201509-citibike-tripdata.csv.gz',\n",
    "                  infer_datetime_format=True,\n",
    "                  parse_dates=['starttime', 'stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new DataFrame by keeping only one column and an index:\n",
    "* select the `starttime` as the index\n",
    "* select the `bikeid` as the only data column\n",
    "* resample by counting the number of `bikeid` values in each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Resample to produce **COUNTS** of bikeids in each hour\n",
    "hourly_bike_count = (df\n",
    "         .set_index('starttime')\n",
    "         .bikeid\n",
    "         .resample('H',how='count')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the resulting DataFrame\n",
    "hourly_bike_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type( hourly_bike_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice the use pattern? Using a succession of `.dot` accessors to transform data is a common use pattern in `pandas`. The parentheses are used purely for scope.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, plotting the data helps you answer questions and helps you ask new ones. Plot the number of riders as a function of start time.\n",
    "* Notice the horizontal axis, range of values\n",
    "* Look for periodicity and trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting with Matplotlib\n",
    "\n",
    "hourly_bike_count.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selecting just one week, take a closer look\n",
    "\n",
    "hourly_bike_count.loc['20150907':'20150914'].plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting with Bokeh provdes interactive tools\n",
    "\n",
    "fig = figure( x_axis_type=\"datetime\", responsive=True, height=200 )\n",
    "\n",
    "# plot line on figure\n",
    "fig.line( hourly_bike_count.index, hourly_bike_count )\n",
    "\n",
    "# Make pretty\n",
    "fig.title            = 'NYC Bicycle Ride Share'\n",
    "fig.xaxis.axis_label = 'Date'\n",
    "fig.yaxis.axis_label = 'Hourly Bike Count'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "* Can you see a daily pattern?\n",
    "* Can you tell weekdays for weekends?\n",
    "* Is there signs of a holiday? Rainy day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is tidied up a bit, it is easy to plot subsets using square backet `[]` index slicing to \"zoom in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Group Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have two populations mixed together, each with different trends:\n",
    "* We need to separate riders by type, e.g. \"casuals\" versus \"regular users\".\n",
    "* Concept of \"split-apply-combine\" work-flow or strategy in analysis. \n",
    "* Pandas supports groupby operations.\n",
    "* Analogous to SQL's GROUP BY and the Excel Pivot Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the full data set, create a new `DataFrame` as follows:\n",
    "* Create a `list` of \"layers\" in a hierarchical index.\n",
    "* Groupby that hierarchical index, first by `starttime`, then by `usertype`\n",
    "* Use pivot to rearrange the `DataFrame` `Index` and `Columns` for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step1 = df.groupby([pd.Grouper(key='starttime',freq='D'),'usertype'])\n",
    "type(step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a `DataFrameGroupBy` object\n",
    "* can be used to perform varous operations.\n",
    "* operations return Series and DataFrames, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: Group by starttime and by usetype, and then count.\n",
    "#    step1.starttime.count() retunrns the total number of non-null values in each column. \n",
    "#    step1.starttime.size() returns the total number of ALL records in each group.\n",
    "\n",
    "step2 = step1.starttime.count()\n",
    "print(type(step2))\n",
    "step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object step2 is a `Series` with a hierarchical index called a `MultiIndex`.\n",
    "\n",
    "We can get back to a `DataFrame` by resetting the index to one \"level\" of the `MultiIndex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step3 = step2.reset_index(level='usertype')\n",
    "print(type(step3))\n",
    "step3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's kind of a mess:\n",
    "* Would be nice to have the data with a single layer index `starttime`\n",
    "* Would be nice to have the different values of `usertype` as columns\n",
    "* use pandas `pivot` to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step4 = step3.pivot(index=step3.index, columns='usertype')\n",
    "step4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the representation could be better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step5 = step4.T.reset_index(level=0,drop=True).T\n",
    "step5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the `pandas` idiomatic way of doing all that, putting it all together, is as follows.\n",
    "\n",
    "Note that ``.reset_index()`` does not currently have an axis argument, so we must transpose, perform the op and transpose again to get the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tidy_df = (df\n",
    "   .groupby([pd.Grouper(key='starttime',freq='D'),'usertype'])\n",
    "   .starttime\n",
    "   .count()\n",
    "   .reset_index(level='usertype')\n",
    "   .pivot(index=step3.index, columns='usertype')\n",
    "   .T.reset_index(level=0,drop=True).T # .reset_index(level=0,axis=1)\n",
    " )\n",
    "tidy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpl_ax1 = tidy_df.plot(figsize=(12,3))\n",
    "mpl_ax1.legend(loc=1)\n",
    "mpl_ax1.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that pd.plot() returns a Matplotlib Axes object! Very useful!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/timeseries.html#dateoffset-objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `Index` that spans 5 days. Notice the defaults:\n",
    "* \"frequency\" is the interval between entries, defaults to \"D\" for \"day\"\n",
    "* \"tz\" is \"timezone\", and defaults to \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "i = pd.date_range('20130101 09:00:00',periods=5)\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offset each element of the `Index` array by 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "i + pd.offsets.Hour(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, explicitly set the \"frequency\" to \"start of months\" (\"MS\") by using the input parameter `freq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "i = pd.date_range('20130101 09:00:00',periods=5,freq='MS')\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, add an offset to each element in the Index:\n",
    "* Notice the behviour for February."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "i + pd.offsets.MonthEnd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very particular offsets are supported. Example: 10 Microseconds (10 $\\mu s$) \n",
    "\n",
    "*Note: $\\mu$ is often denoted \"U\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.date_range(i[0], periods=10, freq='1D10U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Time Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-zone-handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports time zone conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_zones = pd.Series(pd.date_range('20130101 09:00:00',periods=5,tz='US/Eastern'))\n",
    "test_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_zones.dt.tz_convert('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_zones.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time Deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/timedeltas.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Series` of times 1 day plus 2N seconds, for N=0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_deltas = pd.Series(pd.timedelta_range('1 day',periods=5,freq='2 s'))\n",
    "test_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_deltas.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_deltas.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create deltas from a date_range\n",
    "test_range = pd.date_range('20130101 09:00:00',periods=5,freq='MS')\n",
    "test_range - test_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add two different set of deltas\n",
    "test_add = test_deltas + (test_range-test_range[0])\n",
    "test_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Show representation as seconds\n",
    "test_add.astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Show time components, separating days, hours, minutes, seconds...\n",
    "# Notice the days and seconds\n",
    "test_add.dt.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Time Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a demonstration of time series resampling that leads to a problem of missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DateTimeIndex with deltas of milliseconds (ms):\n",
    "rng = pd.date_range('20130101 09:30:00',periods=1000,freq='ms')\n",
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Series` with data generated by adding some random noise to the time index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "test_series = pd.Series(np.random.randn(1000)*.1+50,\n",
    "              index=rng.take(np.random.randint(0, len(rng), size=len(rng)))\n",
    "             )\n",
    "test_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the resulting time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_series.sort_index().plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "resampled_series = test_series.resample('1ms',how='ohlc')\n",
    "resampled_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice the NaN values... what to do?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pandas `.ffill()` method to get rid of NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_series.resample('1ms',how='ohlc').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Computational Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/computation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being some commonly used computation tools for time series in pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.rolling_mean(test_series.sort_index(),freq='10ms',window=1).plot(figsize=(12,6))\n",
    "pd.expanding_mean(test_series.sort_index(),freq='10ms').plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short Demo: Weather Data\n",
    "* Read and resampled data\n",
    "* Computed a Rolling Mean\n",
    "* Visualization with Matplotlib and Bokeh\n",
    "\n",
    "Long Demo: NYC Bicycle Share Data\n",
    "* Download and read data\n",
    "* Resampling, cleaning, tidying data\n",
    "* Group Separation\n",
    "* Data visualization\n",
    "\n",
    "Time Series Operations\n",
    "* Frequency and resampling\n",
    "* Time Zones\n",
    "* Time Deltas\n",
    "* Resampling and time step size\n",
    "* Missing Values\n",
    "* Computational Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "continuum": {
   "depends": [
    "pd_intro",
    "pd_data_structs",
    "pd_tidy"
   ],
   "requires": [
    "data/pittsburgh2013.csv",
    "data/201509-citibike-tripdata.csv.gz"
   ],
   "tag": "pd_series"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
